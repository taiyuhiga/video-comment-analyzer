"""Video Comment Analyzer MCP server implemented with the Python FastMCP helper.

This server provides tools to analyze YouTube video comments using ChatGPT.
It fetches comments from YouTube videos and performs detailed analysis based on
predefined criteria including engagement metrics, viewer sentiment, and improvement suggestions.
"""

from __future__ import annotations

import os
import re
from typing import Any, Dict, List, Optional

import mcp.types as types
from googleapiclient.discovery import build
from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, ConfigDict, Field, ValidationError


class VideoAnalysisInput(BaseModel):
    """Schema for video comment analysis tool."""

    video_url: str = Field(
        ...,
        alias="videoUrl",
        description="YouTubeå‹•ç”»ã®URLï¼ˆä¾‹: https://www.youtube.com/watch?v=VIDEO_IDï¼‰",
    )
    max_comments: int = Field(
        1000,
        alias="maxComments",
        description="å–å¾—ã™ã‚‹æœ€å¤§ã‚³ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ã€å¯èƒ½ãªé™ã‚Šå¤šãå–å¾—ï¼‰",
    )

    model_config = ConfigDict(populate_by_name=True, extra="forbid")


mcp = FastMCP(
    name="video-comment-analyzer",
    stateless_http=True,
)


ANALYSIS_PROMPT = """

ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å‰‡ã£ã¦å…±æœ‰ã—ãŸcsvãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã—ã¦ä¸‹ã•ã„ã€‚

åˆ†æé …ç›®(1)

ãƒ»å…±æ„Ÿæ€§ã®é«˜ã„ã‚³ãƒ¡ãƒ³ãƒˆã®æŠ½å‡º
å…±æ„Ÿæ€§ãŒé«˜ã„ = ã„ã„ã­ã®æ•°ãŒå¤šã„

ãƒ»è¿”ä¿¡ã®æ•°ãŒå¤šã„ã‚³ãƒ¡ãƒ³ãƒˆã®æŠ½å‡º

åˆ†æé …ç›®(2)
ãƒ»å‹•ç”»ã¸ã®è¦æœ›
ãƒ»è¦–è´è€…ã®ä¸æº€
ãƒ»å‹•ç”»ã¸ã®æŒ‡æ‘˜
ãƒ»æ”¹å–„ã‚’å¸Œæœ›ã™ã‚‹å£°
ãƒ»æ‰¹åˆ¤çš„ãªæ„è¦‹

åˆ†æé …ç›®(3)
å‹•ç”»ã®å†…å®¹ã«ã¤ã„ã¦è‚¯å®šçš„ãªæ„è¦‹ã‚„å¦å®šçš„ãªæ„è¦‹ã‚’å®¢è¦³çš„ã«ã¾ã¨ã‚ã¦ã€ä»Šå¾Œè³ªã®é«˜ã„å‹•ç”»ä½œã‚Šã‚’ã™ã‚‹ä¸Šã§ç¶­æŒã™ã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã¦

åˆ†æé …ç›®(4)
åˆ†æé …ç›®1ã€œ3ã‚’ç·åˆçš„ã«åˆ†æã—ã€ä»®ã«ã“ã®å‹•ç”»ã‚’ä½œã‚Šç›´ã™ã“ã¨ã‚’å‰æã¨ã—ã¦ã€ãƒŸã‚¹ã‚’ãªãã—ã€ä¿®æ­£ã™ã¹ããƒã‚¤ãƒ³ãƒˆã¨æ”¹å–„ã™ã¹ããƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã‚‹ã“ã¨

**é‡è¦**: å…¨ã¦ã®åˆ†æçµæœã¯å¿…ãšæ—¥æœ¬èªã§è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

"""


def extract_video_id(url: str) -> Optional[str]:
    """YouTubeã®URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡ºã™ã‚‹"""
    patterns = [
        r'(?:youtube\.com\/watch\?v=)([a-zA-Z0-9_-]+)',
        r'(?:youtube\.com\/embed\/)([a-zA-Z0-9_-]+)',
        r'(?:youtu\.be\/)([a-zA-Z0-9_-]+)',
        r'(?:youtube\.com\/v\/)([a-zA-Z0-9_-]+)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    
    return None


def get_youtube_comments(video_id: str, max_results: int = 100) -> List[Dict[str, Any]]:
    """YouTube Data APIã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹"""
    api_key = os.environ.get('YOUTUBE_API_KEY')
    if not api_key:
        raise ValueError("YOUTUBE_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    youtube = build('youtube', 'v3', developerKey=api_key)
    
    comments = []
    next_page_token = None
    
    while len(comments) < max_results:
        try:
            request = youtube.commentThreads().list(
                part='snippet,replies',
                videoId=video_id,
                maxResults=min(100, max_results - len(comments)),
                pageToken=next_page_token,
                textFormat='plainText',
                order='relevance'
            )
            response = request.execute()
            
            for item in response.get('items', []):
                snippet = item['snippet']['topLevelComment']['snippet']
                comment_data = {
                    'text': snippet['textDisplay'],
                    'author': snippet['authorDisplayName'],
                    'likes': snippet['likeCount'],
                    'reply_count': item['snippet']['totalReplyCount'],
                    'published_at': snippet['publishedAt'],
                }
                comments.append(comment_data)
            
            next_page_token = response.get('nextPageToken')
            if not next_page_token:
                break
                
        except Exception as e:
            raise Exception(f"ã‚³ãƒ¡ãƒ³ãƒˆã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    return comments


def format_comments_for_analysis(comments: List[Dict[str, Any]]) -> str:
    """ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æç”¨ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ•´å½¢ã™ã‚‹"""
    formatted = []
    
    # ã„ã„ã­æ•°ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
    sorted_comments = sorted(comments, key=lambda x: x['likes'], reverse=True)
    
    for i, comment in enumerate(sorted_comments, 1):
        formatted.append(
            f"ã€ã‚³ãƒ¡ãƒ³ãƒˆ {i}ã€‘\n"
            f"æŠ•ç¨¿è€…: {comment['author']}\n"
            f"å†…å®¹: {comment['text']}\n"
            f"ğŸ‘ ã„ã„ã­æ•°: {comment['likes']}\n"
            f"ğŸ’¬ è¿”ä¿¡æ•°: {comment['reply_count']}\n"
            f"ğŸ“… æŠ•ç¨¿æ—¥æ™‚: {comment['published_at']}\n"
        )
    return "\n".join(formatted)


TOOL_INPUT_SCHEMA: Dict[str, Any] = {
    "type": "object",
    "properties": {
        "videoUrl": {
            "type": "string",
            "description": "YouTubeå‹•ç”»ã®URLï¼ˆä¾‹: https://www.youtube.com/watch?v=VIDEO_IDï¼‰",
        },
        "maxComments": {
            "type": "integer",
            "description": "å–å¾—ã™ã‚‹æœ€å¤§ã‚³ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ã€å¯èƒ½ãªé™ã‚Šå¤šãå–å¾—ï¼‰",
            "default": 1000,
        }
    },
    "required": ["videoUrl"],
    "additionalProperties": False,
}


@mcp._mcp_server.list_tools()
async def _list_tools() -> List[types.Tool]:
    return [
        types.Tool(
            name="analyze-video-comments",
            title="å‹•ç”»ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ",
            description="YouTubeå‹•ç”»ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¦ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã€è¦–è´è€…ã®æ„è¦‹ã€æ”¹å–„ç‚¹ãªã©ã‚’è©³ç´°ã«åˆ†æã—ã¾ã™ã€‚",
            inputSchema=TOOL_INPUT_SCHEMA,
            annotations={
                "destructiveHint": False,
                "openWorldHint": True,  # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦
                "readOnlyHint": True,
            },
        )
    ]


async def _call_tool_request(req: types.CallToolRequest) -> types.ServerResult:
    """ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å‡¦ç†ã™ã‚‹"""
    if req.params.name != "analyze-video-comments":
        return types.ServerResult(
            types.CallToolResult(
                content=[
                    types.TextContent(
                        type="text",
                        text=f"ä¸æ˜ãªãƒ„ãƒ¼ãƒ«: {req.params.name}",
                    )
                ],
                isError=True,
            )
        )
    
    arguments = req.params.arguments or {}
    try:
        payload = VideoAnalysisInput.model_validate(arguments)
    except ValidationError as exc:
        return types.ServerResult(
            types.CallToolResult(
                content=[
                    types.TextContent(
                        type="text",
                        text=f"å…¥åŠ›æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {exc.errors()}",
                    )
                ],
                isError=True,
            )
        )
    
    # å‹•ç”»IDã‚’æŠ½å‡º
    video_id = extract_video_id(payload.video_url)
    if not video_id:
        return types.ServerResult(
            types.CallToolResult(
                content=[
                    types.TextContent(
                        type="text",
                        text="æœ‰åŠ¹ãªYouTubeå‹•ç”»URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚",
                    )
                ],
                isError=True,
            )
        )
    
    try:
        # ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
        comments = get_youtube_comments(video_id, payload.max_comments)
        
        if not comments:
            return types.ServerResult(
                types.CallToolResult(
                    content=[
                        types.TextContent(
                            type="text",
                            text="ã“ã®å‹•ç”»ã«ã¯ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€ã¾ãŸã¯ã‚³ãƒ¡ãƒ³ãƒˆãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚",
                        )
                    ],
                    isError=False,
                )
            )
        
        # ã‚³ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã„ã„ã­æ•°ã§ã‚½ãƒ¼ãƒˆæ¸ˆã¿ï¼‰
        comments_text = format_comments_for_analysis(comments)
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
        total_likes = sum(c['likes'] for c in comments)
        total_replies = sum(c['reply_count'] for c in comments)
        avg_likes = total_likes / len(comments) if comments else 0
        
        # ChatGPTã«åˆ†æã‚’ä¾é ¼ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        result_text = f"""# YouTubeå‹•ç”»ã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿

## ğŸ“Š åŸºæœ¬æƒ…å ±
- **å‹•ç”»URL**: {payload.video_url}
- **å‹•ç”»ID**: `{video_id}`
- **å–å¾—ã‚³ãƒ¡ãƒ³ãƒˆæ•°**: {len(comments)}ä»¶
- **åˆè¨ˆã„ã„ã­æ•°**: {total_likes}
- **åˆè¨ˆè¿”ä¿¡æ•°**: {total_replies}
- **å¹³å‡ã„ã„ã­æ•°**: {avg_likes:.1f}

---

## ğŸ“ ã‚³ãƒ¡ãƒ³ãƒˆä¸€è¦§ï¼ˆã„ã„ã­æ•°é †ï¼‰

{comments_text}

---

## ğŸ“‹ åˆ†ææŒ‡ç¤º

{ANALYSIS_PROMPT}
"""
        
        return types.ServerResult(
            types.CallToolResult(
                content=[
                    types.TextContent(
                        type="text",
                        text=result_text,
                    )
                ],
                isError=False,
            )
        )
        
    except Exception as e:
        return types.ServerResult(
            types.CallToolResult(
                content=[
                    types.TextContent(
                        type="text",
                        text=f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                    )
                ],
                isError=True,
            )
        )


mcp._mcp_server.request_handlers[types.CallToolRequest] = _call_tool_request

app = mcp.streamable_http_app()

try:
    from starlette.middleware.cors import CORSMiddleware

    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"],
        allow_credentials=False,
    )
except Exception:
    pass


if __name__ == "__main__":
    import uvicorn

    uvicorn.run("main:app", host="0.0.0.0", port=8003)

